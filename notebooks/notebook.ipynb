{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "dbFile = \"podcasts.db\"\n",
    "\n",
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
    "from ollama import Client\n",
    "import tiktoken\n",
    "from chonkie import SDPMChunker\n",
    "\n",
    "parent_dir = str(Path().resolve().parents[0])\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from app.utils import ShowMetadataList, ShowMetadata, metadata_to_dict\n",
    "\n",
    "data = ShowMetadataList(\n",
    "    shows=[\n",
    "        ShowMetadata(\n",
    "            \"rotl\",\n",
    "            Path(\"../files/meta/rotl_dates.txt\"),\n",
    "            Path(\"../files/meta/rotl_titles.txt\"),\n",
    "        ),\n",
    "        ShowMetadata(\n",
    "            \"roadwork\",\n",
    "            Path(\"../files/meta/roadwork_dates.txt\"),\n",
    "            Path(\"../files/meta/roadwork_titles.txt\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dates_titles = metadata_to_dict(data)\n",
    "\n",
    "dir = Path(\"../files/ariella/\")\n",
    "files = [file for file in dir.iterdir()]\n",
    "\n",
    "out_dir = Path() / \"output\"\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def get_entities(transcript):\n",
    "    names = set()\n",
    "    for line in transcript.splitlines():\n",
    "        speaker, text = line.split(\": \")\n",
    "        entities = model.predict_entities(text, [\"Person\"], threshold=0.5)\n",
    "        for entity in entities:\n",
    "            names.add(entity[\"text\"])\n",
    "    return sorted(list(names))\n",
    "\n",
    "\n",
    "client = Client(host=\"https://mlkyway.anselbrandt.net/ollama\")\n",
    "\n",
    "\n",
    "def ask_llm(context):\n",
    "    response = client.chat(\n",
    "        model=\"gemma2:27b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": context,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    content = response[\"message\"][\"content\"]\n",
    "    return content\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    chunks = text.split(\"\\n\\n\")\n",
    "    response = chunks[1]\n",
    "    return re.sub(r\"\\*\", \"\", response)\n",
    "\n",
    "\n",
    "def get_names(text):\n",
    "    names = clean(text)\n",
    "    return [name.strip() for name in names.splitlines()]\n",
    "\n",
    "\n",
    "chunker = SDPMChunker(\n",
    "    embedding_model=\"minishlab/potion-base-8M\",\n",
    "    threshold=0.5,\n",
    "    chunk_size=512,\n",
    "    min_sentences=1,\n",
    "    skip_window=1,\n",
    "    delim=\"\\n\",\n",
    ")\n",
    "\n",
    "\n",
    "def num_tokens(string: str) -> int:\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def clean_name_response(text):\n",
    "    lines = re.sub(r\"\\n+\", \"\\n\", text).splitlines()\n",
    "    clean_lines = [line for line in lines if \"Let me know if\" not in line]\n",
    "    return \"\\n\".join(clean_lines)\n",
    "\n",
    "\n",
    "def create_chunks_db():\n",
    "    conn = sqlite3.connect(dbFile)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS chunks (\n",
    "        id integer primary key,\n",
    "        filename text,\n",
    "        showname text,\n",
    "        episode text,\n",
    "        title text,\n",
    "        date text,\n",
    "        idx integer,\n",
    "        chunk text\n",
    "        )\"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def create_names_db():\n",
    "    conn = sqlite3.connect(dbFile)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS names (\n",
    "        id integer primary key,\n",
    "        filename text,\n",
    "        showname text,\n",
    "        episode text,\n",
    "        title text,\n",
    "        date text,\n",
    "        name integer,\n",
    "        text text\n",
    "        )\"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def insert_chunks(\n",
    "    chunks, file_name, show_name, episode_number, episode_title, episode_date\n",
    "):\n",
    "    conn = sqlite3.connect(dbFile)\n",
    "    c = conn.cursor()\n",
    "    filename = file_name\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        c.execute(\n",
    "            \"INSERT INTO chunks VALUES (NULL, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "            (\n",
    "                filename,\n",
    "                show_name,\n",
    "                episode_number,\n",
    "                episode_title,\n",
    "                episode_date,\n",
    "                idx,\n",
    "                chunk,\n",
    "            ),\n",
    "        )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def insert_name(\n",
    "    name, text, file_name, show_name, episode_number, episode_title, episode_date\n",
    "):\n",
    "    conn = sqlite3.connect(dbFile)\n",
    "    c = conn.cursor()\n",
    "    filename = file_name\n",
    "    c.execute(\n",
    "        \"INSERT INTO names VALUES (NULL, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "        (\n",
    "            filename,\n",
    "            show_name,\n",
    "            episode_number,\n",
    "            episode_title,\n",
    "            episode_date,\n",
    "            name,\n",
    "            text,\n",
    "        ),\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "create_chunks_db()\n",
    "create_names_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_name = \"Roderick on the Line\"\n",
    "\n",
    "for file in files:\n",
    "    file_name = file.name\n",
    "    episode_number = file_name.split(\"_-_\")[0]\n",
    "    episode_date = dates_titles[\"rotl\"][\"dates\"][episode_number]\n",
    "    episode_title = dates_titles[\"rotl\"][\"titles\"][episode_number]\n",
    "    transcript = open(file, \"r\").read()\n",
    "    chunks = chunker(transcript)\n",
    "    insert_chunks(\n",
    "        chunks, file_name, show_name, episode_number, episode_title, episode_date\n",
    "    )\n",
    "    named_entities = get_entities(transcript)\n",
    "    entities_query = \"Which of these are people's names? Only return results if they are people's names.\"\n",
    "    entities_context = f\"{entities_query}\\n\\n{named_entities}\"\n",
    "    entities_response = ask_llm(entities_context)\n",
    "    names = get_names(entities_response)\n",
    "    for name in names:\n",
    "        relevant_chunks = []\n",
    "        for chunk in chunks:\n",
    "            if name in chunk:\n",
    "                relevant_chunks.append(chunk)\n",
    "        matching_chunks = \"\\n\".join(relevant_chunks)\n",
    "        query = f\"Who is {name}?\"\n",
    "        context = f\"{matching_chunks}\\n\\n{query}\"\n",
    "        name_response = ask_llm(context)\n",
    "        text = clean_name_response(name_response)\n",
    "        insert_name(\n",
    "            name,\n",
    "            text,\n",
    "            file_name,\n",
    "            show_name,\n",
    "            episode_number,\n",
    "            episode_title,\n",
    "            episode_date,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
