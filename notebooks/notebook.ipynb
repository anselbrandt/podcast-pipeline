{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3f75c935a24669b570d5a0a104f046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ansel/ai/podcast-pipeline/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
    "from ollama import Client\n",
    "import tiktoken\n",
    "from chonkie import SDPMChunker\n",
    "\n",
    "parent_dir = str(Path().resolve().parents[0])\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from app.utils import ShowMetadataList, ShowMetadata, metadata_to_dict\n",
    "\n",
    "data = ShowMetadataList(\n",
    "    shows=[\n",
    "        ShowMetadata(\n",
    "            \"rotl\",\n",
    "            Path(\"../files/meta/rotl_dates.txt\"),\n",
    "            Path(\"../files/meta/rotl_titles.txt\"),\n",
    "        ),\n",
    "        ShowMetadata(\n",
    "            \"roadwork\",\n",
    "            Path(\"../files/meta/roadwork_dates.txt\"),\n",
    "            Path(\"../files/meta/roadwork_titles.txt\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dates_titles = metadata_to_dict(data)\n",
    "\n",
    "dir = Path(\"../files/ariella/\")\n",
    "files = [file for file in dir.iterdir()]\n",
    "\n",
    "out_dir = Path() / \"output\"\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def get_entities(transcript):\n",
    "    names = set()\n",
    "    for line in transcript.splitlines():\n",
    "        speaker, text = line.split(\": \")\n",
    "        entities = model.predict_entities(text, [\"Person\"], threshold=0.5)\n",
    "        for entity in entities:\n",
    "            names.add(entity[\"text\"])\n",
    "    return sorted(list(names))\n",
    "\n",
    "\n",
    "client = Client(host=\"https://mlkyway.anselbrandt.net/ollama\")\n",
    "\n",
    "\n",
    "def ask_llm(context):\n",
    "    response = client.chat(\n",
    "        model=\"gemma2:27b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": context,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    content = response[\"message\"][\"content\"]\n",
    "    return content\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    chunks = text.split(\"\\n\\n\")\n",
    "    response = chunks[1]\n",
    "    return re.sub(r\"\\*\", \"\", response)\n",
    "\n",
    "\n",
    "def get_names(text):\n",
    "    names = clean(text)\n",
    "    return names.splitlines()\n",
    "\n",
    "\n",
    "chunker = SDPMChunker(\n",
    "    embedding_model=\"minishlab/potion-base-8M\",\n",
    "    threshold=0.5,\n",
    "    chunk_size=512,\n",
    "    min_sentences=1,\n",
    "    skip_window=1,\n",
    "    delim=\"\\n\",\n",
    ")\n",
    "\n",
    "\n",
    "def num_tokens(string: str) -> int:\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk\n",
    "\n",
    "for file in files[:1]:\n",
    "    file_name = file.name\n",
    "    episode = file_name.split(\"_-_\")[0]\n",
    "    date = dates_titles[\"rotl\"][\"dates\"][episode]\n",
    "    title = dates_titles[\"rotl\"][\"titles\"][episode]\n",
    "    transcript = open(file, \"r\").read()\n",
    "    chunks = chunker(transcript)\n",
    "    chunk_text = [chunk.text for chunk in chunks]\n",
    "    with open(out_dir / \"chunks.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(chunk_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract names\n",
    "\n",
    "for file in files[:1]:\n",
    "    file_name = file.name\n",
    "    episode = file_name.split(\"_-_\")[0]\n",
    "    date = dates_titles[\"rotl\"][\"dates\"][episode]\n",
    "    title = dates_titles[\"rotl\"][\"titles\"][episode]\n",
    "    transcript = open(file, \"r\").read()\n",
    "    chunks = open(\"output/chunks.txt\", \"r\").read().split(\"\\n\\n\")\n",
    "    named_entities = get_entities(transcript)\n",
    "    entities_query = \"Which of these are people's names? Only return results if they are people's names.\"\n",
    "    entities_context = f\"{entities_query}\\n\\n{named_entities}\"\n",
    "    entities_response = ask_llm(entities_context)\n",
    "    names = get_names(entities_response)\n",
    "    with open(out_dir / \"names.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name_response(text):\n",
    "    lines = re.sub(r\"\\n+\", \"\\n\", text).splitlines()\n",
    "    clean_lines = [\n",
    "        line\n",
    "        for line in lines\n",
    "        if \"Let me know if you have any other questions\" not in line\n",
    "    ]\n",
    "    return \"\\n\".join(clean_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Chunk\n",
    "\n",
    "name_dir = Path() / \"names\"\n",
    "name_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for file in files[:1]:\n",
    "    file_name = file.name\n",
    "    episode = file_name.split(\"_-_\")[0]\n",
    "    date = dates_titles[\"rotl\"][\"dates\"][episode]\n",
    "    title = dates_titles[\"rotl\"][\"titles\"][episode]\n",
    "    transcript = open(file, \"r\").read()\n",
    "    chunks = open(\"output/chunks.txt\", \"r\").read().split(\"\\n\\n\")\n",
    "    names = open(\"output/names.txt\", \"r\").read().splitlines()\n",
    "    for name in names:\n",
    "        relevant_chunks = []\n",
    "        for chunk in chunks:\n",
    "            if name in chunk:\n",
    "                relevant_chunks.append(chunk)\n",
    "        matching_chunks = \"\\n\".join(relevant_chunks)\n",
    "        query = f\"Who is {name}?\"\n",
    "        context = f\"{matching_chunks}\\n\\n{query}\"\n",
    "        name_response = ask_llm(context)\n",
    "        response = clean_name_response(name_response)\n",
    "        with open(name_dir / f\"{name}.txt\", \"w\") as f:\n",
    "            f.write(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
